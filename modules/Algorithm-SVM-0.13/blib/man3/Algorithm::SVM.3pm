.\" Automatically generated by Pod::Man v1.37, Pod::Parser v1.32
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sh \" Subsection heading
.br
.if t .Sp
.ne 5
.PP
\fB\\$1\fR
.PP
..
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  | will give a
.\" real vertical bar.  \*(C+ will give a nicer C++.  Capital omega is used to
.\" do unbreakable dashes and therefore won't be available.  \*(C` and \*(C'
.\" expand to `' in nroff, nothing in troff, for use with C<>.
.tr \(*W-|\(bv\*(Tr
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
'br\}
.\"
.\" If the F register is turned on, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.Sh), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.if \nF \{\
.    de IX
.    tm Index:\\$1\t\\n%\t"\\$2"
..
.    nr % 0
.    rr F
.\}
.\"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.hy 0
.if n .na
.\"
.\" Accent mark definitions (@(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2).
.\" Fear.  Run.  Save yourself.  No user-serviceable parts.
.    \" fudge factors for nroff and troff
.if n \{\
.    ds #H 0
.    ds #V .8m
.    ds #F .3m
.    ds #[ \f1
.    ds #] \fP
.\}
.if t \{\
.    ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.    ds #V .6m
.    ds #F 0
.    ds #[ \&
.    ds #] \&
.\}
.    \" simple accents for nroff and troff
.if n \{\
.    ds ' \&
.    ds ` \&
.    ds ^ \&
.    ds , \&
.    ds ~ ~
.    ds /
.\}
.if t \{\
.    ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.    ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.    ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.    ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.    ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.    ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.\}
.    \" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.    \" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.    \" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.    ds : e
.    ds 8 ss
.    ds o a
.    ds d- d\h'-1'\(ga
.    ds D- D\h'-1'\(hy
.    ds th \o'bp'
.    ds Th \o'LP'
.    ds ae ae
.    ds Ae AE
.\}
.rm #[ #] #H #V #F C
.\" ========================================================================
.\"
.IX Title "Algorithm::SVM 3"
.TH Algorithm::SVM 3 "2010-12-16" "perl v5.8.8" "User Contributed Perl Documentation"
.SH "NAME"
Algorithm::SVM \- Perl bindings for the libsvm Support Vector Machine library.
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
.Vb 1
\&  use Algorithm::SVM;
.Ve
.PP
.Vb 2
\&  # Load the model stored in the file 'sample.model'
\&  $svm = new Algorithm::SVM(Model => 'sample.model');
.Ve
.PP
.Vb 4
\&  # Classify a dataset.
\&  $ds1 = new Algorithm::SVM::DataSet(Label => 1,
\&                                     Data  => [0.12, 0.25, 0.33, 0.98]);
\&  $res = $svm->predict($ds);
.Ve
.PP
.Vb 2
\&  # Train a new SVM on some new datasets.
\&  $svm->train(@tset);
.Ve
.PP
.Vb 5
\&  # Change some of the SVM parameters.
\&  $svm->gamma(64);
\&  $svm->C(8);
\&  # Retrain the SVM with the new parameters.
\&  $svm->retrain();
.Ve
.PP
.Vb 2
\&  # Perform cross validation on the training set.
\&  $accuracy = $svm->validate(5);
.Ve
.PP
.Vb 2
\&  # Save the model to a file.
\&  $svm->save('new-sample.model');
.Ve
.PP
.Vb 2
\&  # Load a saved model from a file.
\&  $svm->load('new-sample.model');
.Ve
.PP
.Vb 2
\&  # Retreive the number of classes.
\&  $num = $svm->getNRClass();
.Ve
.PP
.Vb 2
\&  # Retreive labels for dataset classes
\&  (@labels) = $svm->getLabels();
.Ve
.PP
.Vb 2
\&  # Probabilty for regression models, see below for details
\&  $prob = $svm->getSVRProbability();
.Ve
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
Algorithm::SVM implements a Support Vector Machine for Perl.  Support Vector
Machines provide a method for creating classifcation functions from a set of
labeled training data, from which predictions can be made for subsequent data
sets.
.SH "CONSTRUCTOR"
.IX Header "CONSTRUCTOR"
.Vb 2
\&  # Load an existing SVM.
\&  $svm = new Algorithm::SVM(Model  => 'sample.model');
.Ve
.PP
.Vb 5
\&  # Create a new SVM with the specified parameters.
\&  $svm = new Algorithm::SVM(Type   => 'C-SVC',
\&                            Kernel => 'radial',
\&                            Gamma  => 64,
\&                            C      => 8);
.Ve
.PP
An Algorithm::SVM object can be created in one of two ways \- an existing
\&\s-1SVM\s0 can be loaded from a file, or a new \s-1SVM\s0 can be created an trained on
a dataset.
.PP
An existing \s-1SVM\s0 is loaded from a file using the Model named parameter.
The model file should be of the format produced by the svm-train program
(distributed with the libsvm library) or from the \f(CW$svm\fR\->\fIsave()\fR method.
.PP
New \s-1SVM\s0's can be created using the following parameters:
.PP
.Vb 3
\&  Type    - The type of SVM that should be created.  Possible values are:
\&            'C-SVC', 'nu-SVC', 'one-class', 'epsilon-SVR' and 'nu-SVR'.
\&            Default os 'C-SVC'.
.Ve
.PP
.Vb 3
\&  Kernel  - The type of kernel to be used in the SVM.  Possible values
\&            are: 'linear', 'polynomial', 'radial' and 'sigmoid'.
\&            Default is 'radial'.
.Ve
.PP
.Vb 1
\&  Degree  - Sets the degree in the kernel function.  Default is 3.
.Ve
.PP
.Vb 2
\&  Gamma   - Sets the gamme in the kernel function.  Default is 1/k,
\&            where k is the number of training sets.
.Ve
.PP
.Vb 1
\&  Coef0   - Sets the Coef0 in the kernel function.  Default is 0.
.Ve
.PP
.Vb 2
\&  Nu      - Sets the nu parameter for nu-SVC SVM's, one-class SVM's
\&            and nu-SVR SVM's.  Default is 0.5.
.Ve
.PP
.Vb 2
\&  Epsilon - Sets the epsilon in the loss function of epsilon-SVR's.
\&            Default is 0.1.
.Ve
.PP
For a more detailed explanation of what the above parameters actually do,
refer to the documentation distributed with libsvm.
.SH "METHODS"
.IX Header "METHODS"
.Vb 8
\&  $svm->degree($degree);
\&  $svm->gamma($gamma);
\&  $svm->coef0($coef0);
\&  $svm->C($C);
\&  $svm->nu($nu);
\&  $svm->epsilon($epsilon);
\&  $svm->kernel_type($ktype);
\&  $svm->svm_type($svmtype);
.Ve
.PP
.Vb 1
\&  $svm->retrain();
.Ve
.PP
The Algorithm::SVM object provides accessor methods for the various \s-1SVM\s0
parameters.  When a value is provided to the method, the object will
attempt to set the corresponding \s-1SVM\s0 parameter.  If no value is provided,
the current value will be returned.  See the constructor documentation for
a description of appropriate values.
.PP
The retrain method should be called if any of the parameters are modified
from their initial values so as to rebuild the model with the new values.
Note that you can only retrain an \s-1SVM\s0 if you've previously trained the
\&\s-1SVM\s0 on a dataset.  (ie. You can't currently retrain a model loaded with the
load method.)  The method will return a true value if the retraining was
successful and a false value otherwise.
.PP
.Vb 1
\&  $res = $svm->predict($ds);
.Ve
.PP
The predict method is used to classify a set of data according to the
loaded model.  The method accepts a single parameter, which should be
an Algorithm::SVM::DataSet object.  Returns a floating point number
corresponding to the predicted value.
.PP
.Vb 1
\&  $res = $svm->predict_value($ds);
.Ve
.PP
The predict_value method works similar to predict, but returns a
floating point value corresponding to the output of the trained
\&\s-1SVM\s0. For a linear kernel, this can be used to reconstruct the
weights for each attribute as follows: the bias of the linear
function is returned when calling predict_value on an empty dataset
(all zeros), and by setting each variable in turn to one and all
others to zero, you get one value per attribute which corresponds
to bias + weight_i. By subtracting the bias, the final linear
model is obtained as sum of (weight_i * attr_i) plus bias. The
sign of this value corresponds to the binary prediction.
.PP
.Vb 1
\&  $svm->save($filename);
.Ve
.PP
Saves the currently loaded model to the specified filename.  Returns a
false value on failure, and truth value on success.
.PP
.Vb 1
\&  $svm->load($filename);
.Ve
.PP
Loads a model from the specified filename.  Returns a false value on failure,
and truth value on success.
.PP
.Vb 1
\&  $svm->train(@tset);
.Ve
.PP
Trains the \s-1SVM\s0 on a set of Algorithm::SVM::DataSet objects.  \f(CW@tset\fR should
be an array of Algorithm::SVM::DataSet objects.
.PP
.Vb 1
\&  $accuracy = $svm->validate(5);
.Ve
.PP
Performs cross validation on the training set.  If an argument is provided,
the set is partioned into n subsets, and validated against one another.
Returns a floating point number representing the accuracy of the validation.
.PP
.Vb 1
\&  $num = $svm->getNRClass();
.Ve
.PP
For a classification model, this function gives the number of classes.
For a regression or a one-class model, 2 is returned.
.PP
.Vb 1
\&  (@labels) = $svm->getLabels();
.Ve
.PP
For a classification model, this function returns the name of the labels
in an array.  For regression and one-class models undef is returned.
.PP
.Vb 1
\&  $prob = $svm->getSVRProbability();
.Ve
.PP
For a regression model with probability information, this function
outputs a value sigma > 0.  For test data, we consider the probability
model: target value = predicted value + z, z: Laplace distribution
e^(\-|z|/sigma)/2sigma)
.PP
If the model is not for svr or does not contain required information,
undef is returned.
.SH "MAINTAINER"
.IX Header "MAINTAINER"
Matthew Laird <matt@brinkman.mbb.sfu.ca>
Alexander K. Seewald <alex@seewald.at>
.SH "SEE ALSO"
.IX Header "SEE ALSO"
Algorithm::SVM::DataSet and the libsvm homepage:
http://www.csie.ntu.edu.tw/~cjlin/libsvm/
.SH "ACKNOWLEDGEMENTS"
.IX Header "ACKNOWLEDGEMENTS"
Thanks go out to Fiona Brinkman and the other members of the Simon Fraser
University Brinkman Laboratory for providing me the opportunity to develop
this module.  Additional thanks go to Chih-Jen Lin, one of the libsvm authors,
for being particularly helpful during the development process.
.PP
As well to Dr. Alexander K. Seewald of Seewald Solutions for many bug fixes,
new test cases, and lowering the memory footprint by a factor of 20.  Thank
you very much!
